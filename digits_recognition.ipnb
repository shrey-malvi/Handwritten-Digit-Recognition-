{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def preprocess(data):\n",
    "    \n",
    "    (xtrain, ytrain), (xtest, ytest) = data.load_data()\n",
    "    \n",
    "\n",
    "     #Split Dataset into train and test set\n",
    "    xtrain = xtrain.reshape(60000,784)\n",
    "    xtest = xtest.reshape(10000,784)\n",
    "\n",
    "     #Make the value floats in [0:1] instead of int in [0:255]\n",
    "    xtrain = xtrain.astype('float32')\n",
    "    xtest = xtest.astype('float32')\n",
    "    xtrain /= 255\n",
    "    xtest /= 255\n",
    "    digits = 10\n",
    "     #The output variable is an integer from 0 to 9.Convert a class vector (integers) to binary class matrix.\n",
    "    ytrain = to_categorical(ytrain, digits)\n",
    "    ytest = to_categorical(ytest, digits)\n",
    "     \n",
    "    return (xtrain, ytrain), (xtest, ytest)\n",
    "\n",
    "def get_model(input_shape):\n",
    "    neuralnet = Sequential()\n",
    "    neuralnet.add(Dense(512, input_shape=input_shape, activation='relu'))\n",
    "    \n",
    "    neuralnet.add(Dense(512, activation='relu'))\n",
    "    neuralnet.add(Dense(128, activation='relu'))\n",
    "    neuralnet.add(Dense(100, activation='relu'))\n",
    "    neuralnet.add(Dense(10, activation='softmax'))\n",
    "    return neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = preprocess(mnist)\n",
    "model = get_model((784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training ####\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.3214 - acc: 0.8995 - val_loss: 0.1301 - val_acc: 0.9609\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.1049 - acc: 0.9679 - val_loss: 0.1104 - val_acc: 0.9669\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.0683 - acc: 0.9792 - val_loss: 0.0793 - val_acc: 0.9749\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0773 - val_acc: 0.9770\n",
      "Epoch 5/25\n",
      " - 17s - loss: 0.0353 - acc: 0.9890 - val_loss: 0.0720 - val_acc: 0.9819\n",
      "Epoch 6/25\n",
      " - 18s - loss: 0.0285 - acc: 0.9914 - val_loss: 0.0983 - val_acc: 0.9763\n",
      "Epoch 7/25\n",
      " - 19s - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0812 - val_acc: 0.9787\n",
      "Epoch 8/25\n",
      " - 11s - loss: 0.0198 - acc: 0.9940 - val_loss: 0.0945 - val_acc: 0.9789\n",
      "Epoch 9/25\n",
      " - 10s - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0861 - val_acc: 0.9800\n",
      "Epoch 10/25\n",
      " - 10s - loss: 0.0161 - acc: 0.9954 - val_loss: 0.0938 - val_acc: 0.9794\n",
      "Epoch 11/25\n",
      " - 10s - loss: 0.0135 - acc: 0.9957 - val_loss: 0.1384 - val_acc: 0.9762\n",
      "Epoch 12/25\n",
      " - 10s - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0893 - val_acc: 0.9822\n",
      "Epoch 13/25\n",
      " - 10s - loss: 0.0108 - acc: 0.9968 - val_loss: 0.1133 - val_acc: 0.9812\n",
      "Epoch 14/25\n",
      " - 10s - loss: 0.0114 - acc: 0.9969 - val_loss: 0.1088 - val_acc: 0.9799\n",
      "Epoch 15/25\n",
      " - 10s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1656 - val_acc: 0.9760\n",
      "Epoch 16/25\n",
      " - 10s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.1400 - val_acc: 0.9798\n",
      "Epoch 17/25\n",
      " - 10s - loss: 0.0094 - acc: 0.9975 - val_loss: 0.1497 - val_acc: 0.9779\n",
      "Epoch 18/25\n",
      " - 10s - loss: 0.0083 - acc: 0.9977 - val_loss: 0.1354 - val_acc: 0.9803\n",
      "Epoch 19/25\n",
      " - 10s - loss: 0.0088 - acc: 0.9979 - val_loss: 0.1370 - val_acc: 0.9796\n",
      "Epoch 20/25\n",
      " - 10s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1485 - val_acc: 0.9796\n",
      "Epoch 21/25\n",
      " - 10s - loss: 0.0085 - acc: 0.9979 - val_loss: 0.2159 - val_acc: 0.9716\n",
      "Epoch 22/25\n",
      " - 10s - loss: 0.0070 - acc: 0.9983 - val_loss: 0.1618 - val_acc: 0.9795\n",
      "Epoch 23/25\n",
      " - 10s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.1342 - val_acc: 0.9830\n",
      "Epoch 24/25\n",
      " - 10s - loss: 0.0082 - acc: 0.9978 - val_loss: 0.1286 - val_acc: 0.9818\n",
      "Epoch 25/25\n",
      " - 10s - loss: 0.0073 - acc: 0.9983 - val_loss: 0.1635 - val_acc: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b4b0bf358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"#### Training ####\\n\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=25, batch_size=250, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Let's Test on 1 sample ####\n",
      "\n",
      "\n",
      "#### Actual Vector ####\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Test Acc: 0.9774\n"
     ]
    }
   ],
   "source": [
    "print(\"#### Let's Test on 1 sample ####\\n\")\n",
    "print(\"\\n#### Actual Vector ####\\n\" + str(ytest[0:10]))\n",
    "y_test_pred = model.predict(xtest[0:10])\n",
    "acc = model.evaluate(xtest, ytest, verbose=0)\n",
    "print('Test Acc:', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6UlEQVQoFX3BoVrDMBiG0fez1fjpamqHx246NrkHPLuHxIJdLZphWz09j44N+9s9YzE5RzSIBtEgGkSDWEQ/Y/ruMHLOrITZfPXC7J4gjntWwjxP4s5HQsIIU35eeHDMDiNMCYkH3cdm4EqYEhKV6eIyCFNColbGPQhTQqLmo0CYEhI1HwXClJCo+SgQpoREzUeBMCUkaqetQJgSErUyzCDMMTsebU/uExDmeZoH/vXfrzNXYvH2PrrMTT+5ESNWftvtuZkOIwtx4+M8sPBRrMTdcUcYf6EMMytx1/VM5wwXl1mJBtEgGv4AVatLHZBe0aIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAx0lEQVQoFX3BIVIDQRBA0f9tNAfARm8sB8CuRs/eIZ7codeCziWwWUt0fCzYIWmohKqpmvekQzqkQzqkQzqkQzrkZv15OnM1IEn+BOPX85GriiRJwwE2C78qkgTK08vMxE1FkrB93e8W7g4DkqSeHvln9TaCJKnTzN12GKdAktRp5qaybCghSer7B/szFw9jzLsTlJAkAxyO31ys1puFixKSpFVCkrRKSJJWCUnSKiFJWiUkSauEJGmVkCStEpKkVUKStEpI+gFHJTQdxDV8CQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkklEQVQoFX3BoVFDYRAGwP0sGo+OTicUEXqIhx7SBE3EBgsaTw/Hg2Hm3iH+3ViIhdg7vIsWe7ejaLFTiBab+0dc+LieRIvN3cGvr88SLYYSLYYSLYYSLYYSLYYSLYYSLYYSLYYSLYYSLYYSLYYSLfbOz6LF3u0oWmxO/pwfPPlxEcSm/Pf68oZYiIVYiIVYiIVvuVkbHdcJbwYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAApElEQVQoFX3BsVUDMRBF0fcrcRE/pxPSVQ97CFl68KQmphJowjE9CBZxxppE94oFsSAWxL/O0IIkTped7bjz69qCJE7+RPzpLUji9HoPBjtI4tRbMNhBEpUdJFHZQRKVHSRR2UESlR0kUdlBEpUdJFHZQRJVb0ESxc1P3yQxO/b3Zx7E5LodL0zEpDMRiGFjv0Dw0EAMHXj7+KIQC2JBLIgFsfADJC0lHR8qes0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAwklEQVQoFX3BIXbCQBhG0fftAWxTG03s1GOLRQ97YAHs4WcR2UPBNjq2weJrU4aQhClz5l6RITJEhsgQGQKKn+uFweq4YyYwV36cGfTtumMiYj1iImLeNjUjEVucfitGIrL63DcVI/HE8LCpGYmJNxDPxKDYc1e6bt3yIGKL4rt750H8V34txUC8MH88dATiVU/VEIiEkxOBSPAmApHgTQQiwZsIRII3EYgb356ZudJtRSBu+uuF2duyPjQEIkNkiIw/NMkrHaC+3MMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVQoFX3BsXVCMRREwbs9mCIcr1Io4sfk9GAqQSntiNRVOCbFgH2eziaaEQtiQSyIBbEgFsSCCJ++iiLejnvetstZFPHy4F9jiCKShygieTtTRLI7RSS7U0SyO0Uku1NEsjsv21cDkewb1ztPDUS58PSx25/o/BHJ7hSRHqdOEen78EMRaTQmkUZjEmk0JpFGYxJpNCax8AuEARwdmTT7DAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAr0lEQVQoFX3BIU4EQRCG0e+3aLD4xfbYuQRYsNQduAll13OSHr3HKWoqkGzSnX5PLIgFsSAWRApzZkQKc2ZECnNmRApzZkQKc2ZECnPuPFzfKCKFOXdaF0WkMOdO66KIFOb82S/7O4giUphzev3i+WnjchVFpM6/2wfQuihi1LooYtS6KGLUuihi1LooYtT6dnASo8efXZzExPcn2wGImWA7ADET3F4AsSAWxIJY+AWDxiodm4ceLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA80lEQVQoFX3Bq3LCQACG0e+3aKrRwW4sfYjUtjax1DJIhnfYWLDFdmobm9XRrSUaS8NubjV7jogQESJCRIgIERhWO4Jj0xAIzybn9kKQ2azCEw82FxNjSjzRuWYVM6vPNZ7o1Cn/2AJPdOqUucXpBU90rlnFzMftDU90TI0Y5NalBMKzNDcoybHl8Yee6CULWO0MiJGYmDp11Mt9g8MTk3txaSHZ8NoUPIiRLRjdUweIweG3ZLS5PAGidzLPLZM6BUSQb9fM5Ns1IILcOWa+3x0ggty6lIHNy4KOGFhcUwHJ59e5whMT0x4SWO7P9ESEiBARfwfPRR0I6WpvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2ElEQVQoFX3BK3aDQACG0e+3qa3vIgbbTVCb2GEPRMMeBktsJ4vAQi061ejYtgwJr54z94oIESEixD+mfjt5RmLP2eLLE4gdZ0k6JmLLtFXGk9iozfXMTKwVeZewEIvju+XDsxAz01JlrImJJX/xGVti8uPLe8+OGB3q1JfM7j2BGH2mrA0+YyQCZ8XCtIBABM6KjfooEIGzYq01pwuIwFmxMHl6LgEROCtmeXFpKv6IwFnxZF2XEIiJs8V308Nr6vomYyIeDO1tgMPVDzceRISIEBEiQkT8AhC1PB29AMCyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVQoFX3BIVoCQRjH4d+/mjVj3epSwTvYrfPdQSp6h5mqGc8gW5E6ebPcYeTjgYUwz7yvaBANokE0CNdz0a0PHM1xwpWvgbMhMxGuWKJCuGKJCuGKJSqEK5aoEK5YokK4YokK4YolXp5WCddt9xtOhCuWdt34+ou7387yHCdc+Xj7e85cdD8PjyMgXIHlwNVimwcDUReiQNSFKBB1IQrEpB8PTEIUiMl6mY2z2C0E4iqGZJzEkAwQt8r7fgP0u2QciVv95ywDd98rnGgQDaJBNPwDh0w/HdRfXtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 9. 1. 2. 3. 7. 4. 8. 6. 5.]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "y_test_pred=np.zeros((10,10))\n",
    "k=0    \n",
    "def form(img):\n",
    "    def getBestShift(img):\n",
    "        cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "        rows,cols = img.shape\n",
    "        shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "        shifty = np.round(rows/2.0-cy).astype(int)\n",
    "        return shiftx,shifty\n",
    "    def shift(img,sx,sy):\n",
    "        rows,cols = img.shape\n",
    "        M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "        shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "        return shifted\n",
    "    gray=img\n",
    "    gray = cv2.resize(255-gray, (28, 28))\n",
    "    ret, gray = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "    while np.sum(gray[0]) == 0:\n",
    "            gray = gray[1:]\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "            gray = np.delete(gray,0,1)\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "            gray = gray[:-1]\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "            gray = np.delete(gray,-1,1)\n",
    "    rows,cols = gray.shape\n",
    "    if rows > cols:\n",
    "            factor = 20.0/rows\n",
    "            rows = 20\n",
    "            cols = int(round(cols*factor))\n",
    "            gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "            factor = 20.0/cols\n",
    "            cols = 20\n",
    "            rows = int(round(rows*factor))\n",
    "            gray = cv2.resize(gray, (cols, rows))\n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "    shiftx,shifty = getBestShift(gray)\n",
    "    shifted = shift(gray,shiftx,shifty)\n",
    "    gray = shifted\n",
    "    flatten = gray.flatten() / 255.0\n",
    "    return gray\n",
    "img = cv2.imread('test2.png')\n",
    "img2gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img2gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "_, contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "index=1\n",
    "for contour in contours:\n",
    "    [x, y, w, h] = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(100,255,100),2)\n",
    "    cropped = mask[y :y +  h , x : x + w]\n",
    "    s =str(index) + '.png'\n",
    "    if w < 30 and h < 30:\n",
    "        continue\n",
    "    '''\n",
    "    constant= cv2.copyMakeBorder(cropped,10,10,10,10,cv2.BORDER_CONSTANT,(0,0,0))\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion = cv2.dilate(constant,kernel,iterations = 1)\n",
    "    erosion = cv2.erode(erosion,kernel,iterations = 1)\n",
    "    erosion = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    resized = cv2.resize(erosion, dim, interpolation = cv2.INTER_AREA)\n",
    "    '''\n",
    "    resized=form(cropped)\n",
    "   \n",
    "\n",
    "    img2 = resized\n",
    "    img1=img2.reshape(1,784)\n",
    "    y_test_pred[k] = model.predict(img1)\n",
    "    k=k+1\n",
    "    cv2.imwrite(s ,resized)\n",
    "    imgd=Image(s)\n",
    "    display(imgd)\n",
    "   \n",
    "    index = index + 1\n",
    "x=np.round(y_test_pred)\n",
    "m=0\n",
    "final=np.zeros(10)\n",
    "for i in range(10):\n",
    "              for j in range(10):\n",
    "                    if(x[i,j]==1):\n",
    "                        final[m]=j\n",
    "                        m=m+1\n",
    "print(final)\n",
    "cv2.imshow('captcha_result', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
